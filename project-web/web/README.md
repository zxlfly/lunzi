- 图片识别：``usercenter``
- 断点续传、切片、秒传：``upload``
  - 切片
  - 使用``spark-md5``增量计算
  - 使用worker的问题
    - 需要将``spark-md5``复制一份放到``static``静态资源下
    - 不在npm包里面，但是处理大文件性能更好
    - 也可以使用requestIdleCallback
      - 因为是在主线程工作，性能会弱一点

1. 获得文件后，使用 Blob 对象的 slice 方法对其进行切割
2. 使用sparkmd5计算整个文件的 MD5 值，大文件比较耗时，我们将这部分任务放在 Web Worker 中执行。通过FileReader来读文件。
3. 获得文件的 MD5 值之后，我们将 MD5 值发送到后端，后端查询是否存在该文件，如果不存在的话，查询是否存在该文件的切片文件，如果存在，返回切片文件的详细信息。
4. 真正上传之前会处理初步得到的切片，进行遍历为每个切片返回一个新的对象，里面包括name、hash、对应的index、切片文件file以及进度。然后将这些切片打包成一个个单独的上传任务，这里需要生成formdate，formdate包含切片名、文件hash和切片内容，最后用formdate、对应的切片下标和初始为值0的error属性构建请求任务数组。方便后面的请求并发控制，报错重试+次数限制。
5. 开始发起请求时会用stop属性值控制是否继续上传，初始值为false；用count标识已经上传完成的数量，用length标识总共任务的数量，count和length用来判断最终是否完成所有任务。concurrent标识允许的最大并发数量。
内部会有一个循环调用的执行任务的函数。开始就会通过stop判断是否执行。
可以执行就从任务数组头部弹出任务，执行任务
如果失败了就看当前任务的失败次数是否达到允许的最大值，没有就将错误次数+1，从头部加入任务数组，重新执行；如果达到最大值了就将stop改为true，终止整个上传任务。
成功了就判断cut是否等于len-1，
是的就说明已经执行完成所有的上传任务
否则就继续自调，执行下一个任务。并且将已完成数量+1。
任务函数的执行通过while循环控制，只要concurrent值大于0，就调用一次执行任务的函数，并将concurrent-1。以此控制并发
整个请求方法内部用的是一个promise包裹的，成功了就resolve，失败了就reject。

### ``uploadbase``基础的使用上面两种方式实现切片（全量）
### ``uploadsampling``抽样hash
2m为单位，头部取2m，中间的取前中后2个字节，余下的尾部的全要  
抽样hash值不变的情况下不一定没有发生改变，变了就一定改变了。  
### ``uploadslice``切片上传
前面已经实现了文件切片，只需要将对应的切片内容转换成formdate（``let form = new FormData() form.append("name", chunk.name)......``）即可。上传之后后台接受完成，前端需要调用合并接口。
### ``uploadsp``秒传/断点续传
- 算完hash，切片之后询问后端是否上传过，或者上传了一部分
  - 服务器存在对应文件
    - 则提示秒传成功
  - 只存在一部分切片
    - 返回列表，上传是将对应的进度改为100%
    - 上传余下部分
### ``uploadplus``并发数控制，报错重试+次数限制
根据chunks得到对应的要上传的axios的promise，控制数量，失败了重试，同一个任务失败n次后终止整个上传任务。  
此时的chunks的内容格式为``{ form, i: chunk.i ,error:0}``
### @todo关于根据网速。调整每次上传的内容大小
目前想到比较好的方式是，切片的时候将切片控制的小一些，根据网络情况决定每个上传任务上传的切片数量。这种方式只需要算一次切片。
@todo（不重要...）
使用husky限制在commit时跑lint和test；使用commitizen规范提交信息

## 文本编辑器
- marked
- highlightjs

## 富文本编辑器
@todo